{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLADNet_jwkim_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/socome/2019.Spring.AI_Leader/blob/master/VLADNet_jwkim_test_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFa5HXlsEK1",
        "colab_type": "code",
        "outputId": "bfb05001-7599-47ce-ad76-ca05526879e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets, metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8LDbLsXHgtK",
        "colab_type": "code",
        "outputId": "c5779df1-bc93-49e4-c2a8-1e869a181324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.manual_seed(777)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff1e85d3610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsULtEewAJy",
        "colab_type": "code",
        "outputId": "839fd94e-2490-4c69-f995-39feebf72551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Google Drive is mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByNd9eMsFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=7, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        \n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzKKFWksfVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, base_model, net_vlad):\n",
        "        super(EmbedNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.net_vlad = net_vlad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        embedded_x = self.net_vlad(x)\n",
        "        return embedded_x\n",
        "      \n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self, embed_net):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embed_net = embed_net\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        embedded_a = self.embed_net(a)\n",
        "        embedded_p = self.embed_net(p)\n",
        "        embedded_n = self.embed_net(n)\n",
        "        return embedded_a, embedded_p, embedded_n\n",
        "\n",
        "    def feature_extract(self, x):\n",
        "        return self.embed_net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD_yKdlMsZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardTripletLoss(nn.Module):\n",
        "    \"\"\"Hard/Hardest Triplet Loss\n",
        "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin: margin for triplet loss\n",
        "            hardest: If true, loss is considered only hardest triplets.\n",
        "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
        "                If false, output is the pairwise euclidean distance matrix.\n",
        "        \"\"\"\n",
        "        super(HardTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.hardest = hardest\n",
        "        self.squared = squared\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels: labels of the batch, of size (batch_size,)\n",
        "            embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        Returns:\n",
        "            triplet_loss: scalar tensor containing the triplet loss\n",
        "        \"\"\"\n",
        "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
        "\n",
        "        if self.hardest:\n",
        "            # Get the hardest positive pairs\n",
        "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
        "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
        "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Get the hardest negative pairs\n",
        "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
        "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
        "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
        "                    1.0 - mask_anchor_negative)\n",
        "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
        "            triplet_loss = torch.mean(triplet_loss)\n",
        "        else:\n",
        "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
        "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
        "\n",
        "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
        "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "            # and the 2nd (batch_size, 1, batch_size)\n",
        "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
        "\n",
        "            mask = _get_triplet_mask(labels).float()\n",
        "            triplet_loss = loss * mask\n",
        "\n",
        "            # Remove negative losses (i.e. the easy triplets)\n",
        "            triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "            # Count number of hard triplets (where triplet_loss > 0)\n",
        "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
        "            num_hard_triplets = torch.sum(hard_triplets)\n",
        "\n",
        "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
        "\n",
        "        return triplet_loss\n",
        "\n",
        "\n",
        "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
        "    # Compute the 2D matrix of distances between all the embeddings.\n",
        "\n",
        "    cor_mat = torch.matmul(x, x.t())\n",
        "    norm_mat = cor_mat.diag()\n",
        "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
        "    distances = F.relu(distances)\n",
        "\n",
        "    if not squared:\n",
        "        mask = torch.eq(distances, 0.0).float()\n",
        "        distances = distances + mask * eps\n",
        "        distances = torch.sqrt(distances)\n",
        "        distances = distances * (1.0 - mask)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "\n",
        "    mask = indices_not_equal * labels_equal\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "\n",
        "    # Check if labels[i] != labels[k]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "    mask = labels_equal ^ 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
        "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
        "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
        "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
        "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
        "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
        "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
        "\n",
        "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT97DFbsK7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discard layers at the end of base network\n",
        "encoder = resnet18(pretrained=True)\n",
        "base_model = nn.Sequential(\n",
        "    encoder.conv1,\n",
        "    encoder.bn1,\n",
        "    encoder.relu,\n",
        "    encoder.maxpool,\n",
        "    encoder.layer1,\n",
        "    encoder.layer2,\n",
        "    encoder.layer3,\n",
        "    encoder.layer4,\n",
        ")\n",
        "dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "\n",
        "# Define model for embedding\n",
        "net_vlad = NetVLAD(num_clusters=6, dim=dim, alpha=1.0)\n",
        "model = EmbedNet(base_model, net_vlad).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EP9gRLjdhGs",
        "colab_type": "code",
        "outputId": "8d790363-0546-425c-a50c-255d979d6a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dict = torch.load('/content/gdrive/My Drive/AILeader_Dataset/Checkpoint_jw/model_resnet_49.pt')\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XvVkEXTd0sq",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((128,128)),                    #이미지의 크기\n",
        "#     torchvision.transforms.ColorJitter(hue=.05, saturation=.05), #사진의 밝기를 변화시키는 코드\n",
        "#     torchvision.transforms.RandomHorizontalFlip(),               #죄우 대칭을 위한 코드\n",
        "    torchvision.transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "train_imagenet_data = torchvision.datasets.ImageFolder('./gdrive/My Drive/AILeader_Dataset/train', transform=transforms)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_imagenet_data,\n",
        "                                          batch_size=800,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)\n",
        "\n",
        "test_imagenet_data = torchvision.datasets.ImageFolder('./gdrive/My Drive/AILeader_Dataset/test', transform=transforms)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_imagenet_data,\n",
        "                                          shuffle=False,\n",
        "                                          batch_size=126,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPFdi7QL-uH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for train_image,train_label in train_data_loader :\n",
        "  output_train = model(train_image.cuda())\n",
        "  X_train = output_train.cpu().data.numpy()\n",
        "  Y_train = train_label.cpu().data.numpy()\n",
        "  clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
        "  clf.fit(X_train, Y_train)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqKcZT_-ZHTF",
        "colab_type": "code",
        "outputId": "b81326c6-6949-40c2-eed3-89a4b42d5a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "for test_image,test_label in test_data_loader :\n",
        "  \n",
        "  output_test = model(test_image.cuda())\n",
        "  \n",
        "  \n",
        "  X_test = output_test.cpu().data.numpy()\n",
        "  Y_test = test_label.cpu().data.numpy()\n",
        "  \n",
        "  pred = clf.predict(X_test)\n",
        "  \n",
        "  print(pred.shape)\n",
        "  print(Y_test.shape)\n",
        "  \n",
        "  print(metrics.classification_report(Y_test,pred))\n",
        "  print(metrics.confusion_matrix(Y_test,pred))\n",
        "  \n",
        "#   train_pred = clf.predict(X_train)\n",
        "  \n",
        "#   print(train_pred.shape)\n",
        "#   print(Y_train.shape)\n",
        "  \n",
        "#   print(metrics.classification_report(Y_train,train_pred))\n",
        "#   print(metrics.confusion_matrix(Y_train,train_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(125,)\n",
            "(125,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      0.83      0.91        30\n",
            "           2       0.76      0.87      0.81        15\n",
            "           3       0.83      0.88      0.85        33\n",
            "           4       0.94      1.00      0.97        17\n",
            "           5       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           0.91       125\n",
            "   macro avg       0.92      0.93      0.92       125\n",
            "weighted avg       0.92      0.91      0.91       125\n",
            "\n",
            "[[15  0  0  0  0  0]\n",
            " [ 0 25  0  4  1  0]\n",
            " [ 0  0 13  2  0  0]\n",
            " [ 0  0  4 29  0  0]\n",
            " [ 0  0  0  0 17  0]\n",
            " [ 0  0  0  0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwhYeH9Ckjzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}