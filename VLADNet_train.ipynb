{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLADNet_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suimn416/2019.Spring.AI_Leader/blob/master/VLADNet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFa5HXlsEK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8LDbLsXHgtK",
        "colab_type": "code",
        "outputId": "3e379161-3863-491e-ad0c-e4adec82bfea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(777)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff92c4c5670>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ekD3HEdBzND",
        "colab_type": "code",
        "outputId": "425d60ec-2bfa-4555-deab-d0d13c28e48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "tb = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://3da53162.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsULtEewAJy",
        "colab_type": "code",
        "outputId": "93093e16-dceb-4ec8-8b94-944e9abb882d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Google Drive is already mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7qv_b9jUqAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prof_team = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVXFtGxtVGPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if prof_team :\n",
        "  ckpt_path = '/content/gdrive/My Drive/AILeader_Dataset/Checkpoint_jw'\n",
        "  train_path = './gdrive/My Drive/AILeader_Dataset/train'\n",
        "  test_path = './gdrive/My Drive/AILeader_Dataset/test'\n",
        "\n",
        "else :\n",
        "  ckpt_path = './gdrive/My Drive/ckpt'\n",
        "  train_path = './gdrive/My Drive/train'\n",
        "  test_path = './gdrive/My Drive/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByNd9eMsFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=7, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        \n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzKKFWksfVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, base_model, net_vlad):\n",
        "        super(EmbedNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.net_vlad = net_vlad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        embedded_x = self.net_vlad(x)\n",
        "        return embedded_x\n",
        "      \n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self, embed_net):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embed_net = embed_net\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        embedded_a = self.embed_net(a)\n",
        "        embedded_p = self.embed_net(p)\n",
        "        embedded_n = self.embed_net(n)\n",
        "        return embedded_a, embedded_p, embedded_n\n",
        "\n",
        "    def feature_extract(self, x):\n",
        "        return self.embed_net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD_yKdlMsZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardTripletLoss(nn.Module):\n",
        "    \"\"\"Hard/Hardest Triplet Loss\n",
        "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin: margin for triplet loss\n",
        "            hardest: If true, loss is considered only hardest triplets.\n",
        "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
        "                If false, output is the pairwise euclidean distance matrix.\n",
        "        \"\"\"\n",
        "        super(HardTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.hardest = hardest\n",
        "        self.squared = squared\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels: labels of the batch, of size (batch_size,)\n",
        "            embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        Returns:\n",
        "            triplet_loss: scalar tensor containing the triplet loss\n",
        "        \"\"\"\n",
        "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
        "\n",
        "        if self.hardest:\n",
        "            # Get the hardest positive pairs\n",
        "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
        "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
        "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Get the hardest negative pairs\n",
        "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
        "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
        "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
        "                    1.0 - mask_anchor_negative)\n",
        "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
        "            triplet_loss = torch.mean(triplet_loss)\n",
        "        else:\n",
        "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
        "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
        "\n",
        "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
        "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "            # and the 2nd (batch_size, 1, batch_size)\n",
        "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
        "\n",
        "            mask = _get_triplet_mask(labels).float()\n",
        "            triplet_loss = loss * mask\n",
        "\n",
        "            # Remove negative losses (i.e. the easy triplets)\n",
        "            triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "            # Count number of hard triplets (where triplet_loss > 0)\n",
        "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
        "            num_hard_triplets = torch.sum(hard_triplets)\n",
        "\n",
        "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
        "\n",
        "        return triplet_loss\n",
        "\n",
        "\n",
        "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
        "    # Compute the 2D matrix of distances between all the embeddings.\n",
        "\n",
        "    cor_mat = torch.matmul(x, x.t())\n",
        "    norm_mat = cor_mat.diag()\n",
        "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
        "    distances = F.relu(distances)\n",
        "\n",
        "    if not squared:\n",
        "        mask = torch.eq(distances, 0.0).float()\n",
        "        distances = distances + mask * eps\n",
        "        distances = torch.sqrt(distances)\n",
        "        distances = distances * (1.0 - mask)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "\n",
        "    mask = indices_not_equal * labels_equal\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "\n",
        "    # Check if labels[i] != labels[k]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "    mask = labels_equal ^ 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
        "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
        "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
        "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
        "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
        "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
        "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
        "\n",
        "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGfXSFKV0wpB",
        "colab_type": "code",
        "outputId": "5aab9089-2000-4155-cdd5-fed833b85f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3009
        }
      },
      "source": [
        "models.resnet50()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7-PPiWqwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(model_name, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    base_model = None\n",
        "    dim = 0\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        encoder = models.resnet18(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        encoder = models.resnet18(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        encoder = models.alexnet(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "\n",
        "    elif model_name == \"vgg16\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        encoder = models.vgg16(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "  \n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        encoder = models.densenet121(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == 'mobilenet':\n",
        "        \"\"\" mobilenet_v2\n",
        "        \"\"\"\n",
        "        encoder = models.mobilenet_v2(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "       \n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        \n",
        "\n",
        "    return base_model, dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RQvaki_q6HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'resnet50'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II8pCYsnq4E1",
        "colab_type": "code",
        "outputId": "1f0bd9a3-0ddc-43cf-fd3f-3073ff24ce9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Initialize the model for this run\n",
        "base_model, dim = initialize_model(model_name,use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print('dim :',dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dim : 512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT97DFbsK7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model for embedding\n",
        "net_vlad = NetVLAD(num_clusters=7, dim=dim, alpha=1.0)\n",
        "model = EmbedNet(base_model, net_vlad).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHsPHtrsp4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss\n",
        "criterion = HardTripletLoss(margin=0.1).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkRFjLlMEcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfD-ILt-2BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((128,128)),                    #이미지의 크기\n",
        "#     torchvision.transforms.ColorJitter(hue=.05, saturation=.05), #사진의 밝기를 변화시키는 코드\n",
        "#     torchvision.transforms.RandomHorizontalFlip(),               #죄우 대칭을 위한 코드\n",
        "    torchvision.transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "\n",
        "train_imagenet_data = torchvision.datasets.ImageFolder(train_path, transform=transforms)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_imagenet_data,\n",
        "                                          batch_size=8,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)\n",
        "test_imagenet_data = torchvision.datasets.ImageFolder(test_path, transform=transforms)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_imagenet_data,\n",
        "                                          shuffle=False,\n",
        "                                          batch_size=105,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPFdi7QL-uH",
        "colab_type": "code",
        "outputId": "4aa00e92-8b49-4e74-d37c-37df627f0c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "source": [
        "globaliter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (train_image,train_label) in enumerate(train_data_loader) :\n",
        "    output_train = model(train_image.cuda())\n",
        "    triplet_loss = criterion(output_train, train_label.cuda())\n",
        "    optimizer.zero_grad()\n",
        "    triplet_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    # This is where I'm recording to Tensorboard\n",
        "    tb.save_value('Train Loss', 'train_loss', globaliter, triplet_loss.item())\n",
        "    print(epoch,globaliter,batch_idx,triplet_loss.item())\n",
        "    globaliter += 1\n",
        "  model_save_name = 'model_{}.pt'.format(epoch)\n",
        "  path = os.path.join(ckpt_path,model_save_name)\n",
        "  torch.save(model.state_dict(), path)\n",
        " \n",
        "#   X = output_train.cpu().data.numpy()\n",
        "#   Y = label_train.cpu().data.numpy()\n",
        "#   clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
        "#   clf.fit(X, Y) \n",
        "    \n",
        "#   for test_image,test_label in test_data_loader :\n",
        "#     output_test = model(output_test.cuda())\n",
        "#     X_test = output_test.cpu().data.numpy()\n",
        "#     Y_test = label_test.numpy()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0 0.09823809564113617\n",
            "0 1 1 0.09782741963863373\n",
            "0 2 2 0.09243568778038025\n",
            "0 3 3 0.09652654081583023\n",
            "0 4 4 0.09803703427314758\n",
            "0 5 5 0.09875950217247009\n",
            "0 6 6 0.09675021469593048\n",
            "0 7 7 0.09745565056800842\n",
            "0 8 8 0.0975135937333107\n",
            "0 9 9 0.0970083698630333\n",
            "0 10 10 0.09823018312454224\n",
            "0 11 11 0.09557074308395386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0286d0dc988c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtriplet_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \"\"\"\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOqeXkVy4O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}